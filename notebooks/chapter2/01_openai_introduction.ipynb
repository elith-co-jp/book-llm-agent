{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# OpenAI API キーの設定\n",
    "api_key = getpass.getpass(\"OpenAI API キーを入力してください: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 テキスト生成の基礎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキスト生成の基本的な流れ\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    temperature=0.0,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"こんにちは\"}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルな対話 AI の作成\n",
    "\n",
    "history = []\n",
    "n = 10  # 会話の上限\n",
    "model = \"gpt-4o-mini\"\n",
    "for _ in range(n):\n",
    "    user_input = input(\"ユーザ入力: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    print(f\"ユーザ: {user_input}\")\n",
    "    history.append({\"role\": \"user\", \"content\": user_input})\n",
    "    response = client.chat.completions.create(model=model, messages=history)\n",
    "    content = response.choices[0].message.content\n",
    "    print(f\"AI: {content}\")\n",
    "    history.append({\"role\": \"assistant\", \"content\": content})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 テキスト生成の応用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成できた部分から順に表示する\n",
    "\n",
    "history = []\n",
    "n = 10  # 会話の上限\n",
    "model = \"gpt-4o-mini\"\n",
    "for _ in range(n):\n",
    "    user_input = input(\"ユーザ入力: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    print(f\"ユーザ: {user_input}\")\n",
    "    history.append({\"role\": \"user\", \"content\": user_input})\n",
    "    # stream=True でストリーミングを有効化\n",
    "    stream = client.chat.completions.create(model=model, messages=history, stream=True)\n",
    "    print(\"AI: \", end=\"\")\n",
    "    # 応答を集める文字列\n",
    "    ai_content = \"\"\n",
    "    # ストリーミングの各チャンクを処理\n",
    "    for chunk in stream:\n",
    "        # message ではなく ChoiceDelta\n",
    "        content = chunk.choices[0].delta.content\n",
    "        # ChoiceDelta の finish_reason が stop なら生成完了\n",
    "        if chunk.choices[0].finish_reason == \"stop\":\n",
    "            break\n",
    "        print(content, end=\"\")\n",
    "        ai_content += content\n",
    "    print()\n",
    "    history.append({\"role\": \"assistant\", \"content\": ai_content})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大公約数を求めるツールの利用\n",
    "\n",
    "gcd_function = {\n",
    "    \"name\": \"gcd\",\n",
    "    \"description\": \"最大公約数を求める\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"num1\": {\"type\": \"number\", \"description\": \"整数1\"},\n",
    "            \"num2\": {\"type\": \"number\", \"description\": \"整数2\"},\n",
    "        },\n",
    "        \"required\": [\"num1\", \"num2\"],\n",
    "    },\n",
    "}\n",
    "tools = [{\"type\": \"function\", \"function\": gcd_function}]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"50141 と 53599 の最大公約数を求めてください。\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", messages=messages, tools=tools\n",
    ")\n",
    "print(response.choices[0].message.content)  # None\n",
    "print(response.choices[0].finish_reason)  # tool_calls\n",
    "print(response.choices[0].message.tool_calls)  # [ChatCompletionMessageToolCall(...)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数情報を抽出\n",
    "\n",
    "import json\n",
    "\n",
    "function_info = response.choices[0].message.tool_calls[0].function\n",
    "name = function_info.name\n",
    "args = json.loads(function_info.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大公約数の計算\n",
    "\n",
    "import math\n",
    "\n",
    "print(math.gcd(args[\"num1\"], args[\"num2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic を用いた関数の定義\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class GCD(BaseModel):\n",
    "    num1: int = Field(description=\"整数1\")\n",
    "    num2: int = Field(description=\"整数2\")\n",
    "\n",
    "\n",
    "gcd_function = {\n",
    "    \"name\": \"gcd\",\n",
    "    \"description\": \"最大公約数を求める\",\n",
    "    \"parameters\": GCD.model_json_schema(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": gcd_function}]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"50141 と 53599 の最大公約数を求めてください。\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", messages=messages, tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic を用いた引数の取得\n",
    "\n",
    "parsed_result = GCD.model_validate_json(\n",
    "    response.choices[0].message.tool_calls[0].function.arguments\n",
    ")\n",
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ツール利用全体の流れ\n",
    "\n",
    "\n",
    "class LCM(BaseModel):\n",
    "    num1: int = Field(description=\"整数1\")\n",
    "    num2: int = Field(description=\"整数2\")\n",
    "\n",
    "\n",
    "lcm_function = {\n",
    "    \"name\": \"lcm\",\n",
    "    \"description\": \"最小公倍数を求める\",\n",
    "    \"parameters\": LCM.model_json_schema(),\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": gcd_function},\n",
    "    {\"type\": \"function\", \"function\": lcm_function},\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"50141 と 53599 の最大公約数と最小公倍数を求めてください。\",\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", messages=messages, tools=tools\n",
    ")\n",
    "choice = response.choices[0]\n",
    "if choice.finish_reason == \"tool_calls\":\n",
    "    for tool in choice.message.tool_calls:\n",
    "        if tool.function.name == \"gcd\":\n",
    "            gcd_args = GCD.model_validate_json(tool.function.arguments)\n",
    "            print(f\"最大公約数: {math.gcd(gcd_args.num1, gcd_args.num2)}\")\n",
    "        elif tool.function.name == \"lcm\":\n",
    "            lcm_args = LCM.model_validate_json(tool.function.arguments)\n",
    "            print(f\"最小公倍数: {math.lcm(lcm_args.num1, lcm_args.num2)}\")\n",
    "elif choice.finish_reason == \"stop\":\n",
    "    print(\"AI: \", choice.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### response_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_format の利用例\n",
    "\n",
    "\n",
    "class Translations(BaseModel):\n",
    "    english: str = Field(description=\"英語の文章\")\n",
    "    french: str = Field(description=\"フランス語の文章\")\n",
    "    chinese: str = Field(description=\"中国語の文章\")\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\\\n",
    "以下に示す文章を英語・フランス語・中国語に翻訳してください。\n",
    "ただし、アウトプットは後述するフォーマットの JSON 形式で出力してください。\n",
    "\n",
    "# 文章\n",
    "吾輩は猫である。名前はまだない。\n",
    "\n",
    "# 出力フォーマット\n",
    "以下に JSON Schema 形式のフォーマットを示します。このフォーマットに従うオブジェクトの形で出力してください。\n",
    "{Translations.model_json_schema()}\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    temperature=0.0,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "translations = Translations.model_validate_json(response.choices[0].message.content)\n",
    "print(\"英語:\", translations.english)\n",
    "print(\"フランス語:\", translations.french)\n",
    "print(\"中国語:\", translations.chinese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\\\n",
    "以下に示す文章を英語・フランス語・中国語に翻訳してください。\n",
    "ただし、アウトプットは後述するフォーマットの JSON 形式で出力してください。\n",
    "\n",
    "# 文章\n",
    "吾輩は猫である。名前はまだない。\n",
    "\n",
    "# 出力フォーマット\n",
    "JSON Schema に従う形式で出力してください。\n",
    "\"\"\"\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    temperature=0.0,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format=Translations,\n",
    ")\n",
    "translations = response.choices[0].message.parsed\n",
    "\n",
    "print(\"英語:\", translations.english)\n",
    "print(\"フランス語:\", translations.french)\n",
    "print(\"中国語:\", translations.chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.3 画像を入力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def image2content(image_path: Path) -> dict[str, Any]:\n",
    "    # base64 エンコード\n",
    "    with image_path.open(\"rb\") as f:\n",
    "        image_base64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    # content の作成\n",
    "    content = {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\", \"detail\": \"low\"},\n",
    "    }\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"これは何の画像ですか?\"\n",
    "image_path = Path(\"./sample_image1.png\")\n",
    "contents = [{\"type\": \"text\", \"text\": prompt}, image2content(image_path)]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    "    messages=[{\"role\": \"user\", \"content\": contents}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path2 = Path(\"./sample_image2.png\")\n",
    "\n",
    "prompt = \"2枚の画像の違いを教えてください。\"\n",
    "contents = [\n",
    "    {\"type\": \"text\", \"text\": prompt},\n",
    "    image2content(image_path),\n",
    "    image2content(image_path2),\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    "    messages=[{\"role\": \"user\", \"content\": contents}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.4 音声を扱う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音声を文字起こしする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "audio_path = Path(\"./sample_audio.mp3\")\n",
    "\n",
    "with audio_path.open(\"rb\") as f:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\", file=f, temperature=0.0\n",
    "    )\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プロンプトを用いて文字起こしする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"下垣内\"\n",
    "\n",
    "with audio_path.open(\"rb\") as f:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=f,\n",
    "        prompt=prompt,\n",
    "        response_format=\"text\",\n",
    "        temperature=0.0,\n",
    "    )\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音声を合成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_output_path = Path(\"output.mp3\")\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=\"こんにちは。私は AI アシスタントです！\",\n",
    ") as response:\n",
    "    response.stream_to_file(audio_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.5 画像を生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import requests\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"\"\"\\\n",
    "メタリックな球体\n",
    "\"\"\"\n",
    "\n",
    "response = client.images.generate(\n",
    "    model=\"dall-e-3\", prompt=prompt, n=1, size=\"1024x1024\"\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url\n",
    "image = requests.get(image_url).content\n",
    "with open(\"output1.png\", \"wb\") as f:\n",
    "    f.write(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.images.generate(\n",
    "    model=\"dall-e-3\", prompt=prompt, n=1, size=\"1024x1024\", response_format=\"b64_json\"\n",
    ")\n",
    "\n",
    "image = response.data[0].b64_json\n",
    "\n",
    "with open(\"output2.png\", \"wb\") as f:\n",
    "    f.write(base64.b64decode(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.data[0].revised_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
