{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGQrvXao8Ue5"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmgwxvC071EL",
        "outputId": "a70e637f-f7dd-4a9f-f6f5-9dce992bcee5"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# OpenAI API キーの設定\n",
        "api_key = getpass.getpass(\"OpenAI API キーを入力してください: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzCRyhnb9Kf6",
        "outputId": "88a3a00c-94db-4f9b-e9bc-532b018f772f"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langgraph langchain-openai langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vXW4rC68Xd0"
      },
      "source": [
        "# 4.1 マルチエージェントシステムの構築"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQGJiFm_8ko0"
      },
      "source": [
        "## 4.2.2 チャットボットの構築"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rGTXx5dG9BvR"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "class State(TypedDict):\n",
        "    count: int\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "def chatbot(state: State):\n",
        "    messages = [llm.invoke(state[\"messages\"])]\n",
        "    count = state[\"count\"] + 1\n",
        "    return {\n",
        "        \"messages\": messages,\n",
        "        \"count\": count,\n",
        "    }\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "OTFpGOgy9CYN",
        "outputId": "5d2657be-8ebb-4f6d-daa4-ae1678f319ad"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC1svxRU9CVi",
        "outputId": "1d81751c-385f-472c-96ee-1777cbbf2000"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "\n",
        "human_message = HumanMessage(\"こんにちは\")\n",
        "\n",
        "for event in graph.stream({\"messages\": [human_message], \"count\": 0}):\n",
        "    for value in event.values():\n",
        "        print(f\"### ターン{value['count']} ###\")\n",
        "        value[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SlU1rU3W9CTS"
      },
      "outputs": [],
      "source": [
        "# ペルソナの設定\n",
        "\n",
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    system_message = SystemMessage(\"あなたは、元気なエンジニアです。元気に返答してください。\")\n",
        "    messages = [llm.invoke([system_message] + state[\"messages\"])]\n",
        "    count = state[\"count\"] + 1\n",
        "    return {\n",
        "        \"messages\": messages,\n",
        "        \"count\": count,\n",
        "    }\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMyO_d8z9CQq",
        "outputId": "5c8adb6c-465c-4523-ad36-bb774507e6fb"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "\n",
        "human_message = HumanMessage(\"上手くデバッグができません\")\n",
        "\n",
        "for event in graph.stream({\"messages\": [human_message], \"count\": 0}):\n",
        "    for value in event.values():\n",
        "        print(f\"### ターン{value['count']} ###\")\n",
        "        value[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHXlL21f8klr"
      },
      "source": [
        "## 4.2.3 複数のエージェントの接続"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHD2smCU8kiz"
      },
      "source": [
        "### 3つのエージェントの準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2_SGC-du_nt2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langchain.prompts import SystemMessagePromptTemplate\n",
        "import functools\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "def agent_with_persona(state: State, name: str, traits: str):\n",
        "    system_message_template = SystemMessagePromptTemplate.from_template(\n",
        "        \"あなたの名前は{name}です。\\nあなたの性格は以下のとおりです。\\n\\n{traits}\"\n",
        "    )\n",
        "    system_message = system_message_template.format(name=name, traits=traits)\n",
        "\n",
        "    message = HumanMessage(\n",
        "        content=llm.invoke([system_message, *state[\"messages\"]]).content,\n",
        "        name=name,\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"messages\": [message],\n",
        "    }\n",
        "\n",
        "kenta_traits = \"\"\"\\\n",
        "- アクティブで冒険好き\n",
        "- 新しい経験を求める\n",
        "- アウトドア活動を好む\n",
        "- SNSでの共有を楽しむ\n",
        "- エネルギッシュで社交的\"\"\"\n",
        "\n",
        "mari_traits = \"\"\"\\\n",
        "- 穏やかでリラックス志向\n",
        "- 家族を大切にする\n",
        "- 静かな趣味を楽しむ\n",
        "- 心身の休養を重視\n",
        "- 丁寧な生活を好む\"\"\"\n",
        "\n",
        "yuta_traits = \"\"\"\\\n",
        "- バランス重視\n",
        "- 柔軟性がある\n",
        "- 自己啓発に熱心\n",
        "- 伝統と現代の融合を好む\n",
        "- 多様な経験を求める\"\"\"\n",
        "\n",
        "kenta = functools.partial(agent_with_persona, name=\"kenta\", traits=kenta_traits)\n",
        "mari = functools.partial(agent_with_persona, name=\"mari\", traits=mari_traits)\n",
        "yuta = functools.partial(agent_with_persona, name=\"yuta\", traits=yuta_traits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2KaKU0-8kf2"
      },
      "source": [
        "### 3つのエージェントが順番に回答するシステム"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xvcbBjzf_wtB"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Sw6t5kaDAY_Q"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "graph_builder.add_node(\"kenta\", kenta)\n",
        "graph_builder.add_node(\"mari\", mari)\n",
        "graph_builder.add_node(\"yuta\", yuta)\n",
        "\n",
        "graph_builder.add_edge(START, \"kenta\")\n",
        "graph_builder.add_edge(\"kenta\", \"mari\")\n",
        "graph_builder.add_edge(\"mari\", \"yuta\")\n",
        "graph_builder.add_edge(\"yuta\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "fny-Bwr_AZnR",
        "outputId": "caa45ccd-e549-401b-badb-e94b7129c2ca"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIM6amN9AdHA",
        "outputId": "23a08647-d075-4f0b-a3d5-71127e9a13ef"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "human_message = HumanMessage(\"休日の過ごし方について、建設的に議論してください。\")\n",
        "\n",
        "for event in graph.stream({\"messages\": [human_message]}):\n",
        "    for value in event.values():\n",
        "        value[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1k-Vxu08kdN"
      },
      "source": [
        "### 3つのエージェントが一斉に回答するシステム"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "F5KR9ZG7AiFt"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "graph_builder.add_node(\"kenta\", kenta)\n",
        "graph_builder.add_node(\"mari\", mari)\n",
        "graph_builder.add_node(\"yuta\", yuta)\n",
        "\n",
        "\n",
        "graph_builder.add_edge(START, \"kenta\")\n",
        "graph_builder.add_edge(START, \"mari\")\n",
        "graph_builder.add_edge(START, \"yuta\")\n",
        "graph_builder.add_edge(\"kenta\", END)\n",
        "graph_builder.add_edge(\"mari\", END)\n",
        "graph_builder.add_edge(\"yuta\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "678fnvYyAnis",
        "outputId": "39f36816-1890-46b1-be0f-ba50779f24bd"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7F4qNwWAu04",
        "outputId": "639b0b81-d4b6-4fc5-dc4f-edbcbe44c233"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "\n",
        "human_message = HumanMessage(\"休日の過ごし方について、建設的に議論してください。\")\n",
        "\n",
        "for event in graph.stream({\"messages\": [human_message]}):\n",
        "    for value in event.values():\n",
        "        value[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q-P5_Wr8kaD"
      },
      "source": [
        "### 3つのエージェントから選択されたエージェントが回答するシステム"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "xnYkNzNmAyf8"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain.prompts import SystemMessagePromptTemplate\n",
        "from typing import Literal\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    next: str\n",
        "\n",
        "member_dict = {\n",
        "    \"kenta\": kenta_traits,\n",
        "    \"mari\": mari_traits,\n",
        "    \"yuta\": yuta_traits,\n",
        "}\n",
        "\n",
        "#1 スキーマの設定\n",
        "class RouteSchema(BaseModel):\n",
        "    next: Literal[\"kenta\", \"mari\", \"yuta\"] = Field(..., description=\"次に発言する人\")\n",
        "\n",
        "#2 監督者の作成\n",
        "def supervisor(state: State):\n",
        "    system_message = SystemMessagePromptTemplate.from_template(\n",
        "        \"あなたは以下の作業者間の会話を管理する監督者です：{members}。\"        \"各メンバーの性格は以下の通りです。\"        \"{traits_description}\"        \"与えられたユーザーリクエストに対して、次に発言する人を選択してください。\"    )\n",
        "\n",
        "    members = \", \".join(list(member_dict.keys()))\n",
        "    traits_description = \"\\n\".join([f\"**{name}**\\n{traits}\" for name, traits in member_dict.items()])\n",
        "\n",
        "    system_message = system_message.format(members=members, traits_description=traits_description)\n",
        "\n",
        "    llm_with_format = llm.with_structured_output(RouteSchema)\n",
        "\n",
        "    next = llm_with_format.invoke([system_message] + state[\"messages\"]).next\n",
        "    return {\"next\": next}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "_Tesz8AvBMBg"
      },
      "outputs": [],
      "source": [
        "graph_builder = StateGraph(State)\n",
        "\n",
        "graph_builder.add_node(\"supervisor\", supervisor)\n",
        "graph_builder.add_node(\"kenta\", kenta)\n",
        "graph_builder.add_node(\"mari\", mari)\n",
        "graph_builder.add_node(\"yuta\", yuta)\n",
        "\n",
        "graph_builder.add_edge(START, \"supervisor\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda state: state[\"next\"],\n",
        "    {\"kenta\": \"kenta\", \"mari\": \"mari\", \"yuta\": \"yuta\"},\n",
        ")\n",
        "\n",
        "for member in [\"kenta\", \"mari\", \"yuta\"]:\n",
        "    graph_builder.add_edge(member, END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "C_745661BQmW",
        "outputId": "65c802d3-8ce6-4b0a-cec2-276c32820528"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZL-CGsZBiWU",
        "outputId": "36639c7b-343e-4a0a-a61f-c3544b1bb349"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "human_message = HumanMessage(\"休日のまったりした過ごし方を教えて\")\n",
        "for event in graph.stream({\"messages\": [human_message]}):\n",
        "    for value in event.values():\n",
        "        if \"next\" in value:\n",
        "            print(f\"次に発言する人: {value['next']}\")\n",
        "        elif \"messages\" in value:\n",
        "            value[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sek8AwOc8kWU"
      },
      "source": [
        "## 4.2.4 ツールの使用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVq61UlQ_ePY"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# Tavily API キーの設定\n",
        "api_key = getpass.getpass(\"Tavily API キーを入力してください: \")\n",
        "os.environ[\"TAVILY_API_KEY\"] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6Jf8Lmrh78vS"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "#1 ツールの作成\n",
        "tavily_tool = TavilySearchResults(max_results=2)\n",
        "\n",
        "#2 ツールの紐づけ\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "llm_with_tool = llm.bind_tools([tavily_tool])\n",
        "\n",
        "#3 ツールを使ったチャットボットの作成\n",
        "def chatbot(state: State):\n",
        "    messages = [llm_with_tool.invoke(state[\"messages\"])]\n",
        "    return {\n",
        "        \"messages\": messages,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LO7MA1Iq-Gxx"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "\n",
        "class ToolNode:\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, state: State):\n",
        "        #1 最後のメッセージを取得\n",
        "        if messages := state.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"入力にメッセージが見つかりません\")\n",
        "\n",
        "        #2 ツールの実行\n",
        "        tool_messages = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            #2.1 エージェントが指定したnameとargsを元にツールを実1行\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            #2.2 ツールの実行結果をメッセージとして追加\n",
        "            tool_messages.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result, ensure_ascii=False),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return {\n",
        "            \"messages\": tool_messages,\n",
        "        }\n",
        "\n",
        "tool_node = ToolNode([tavily_tool])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XNfI5sO7-e2e"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "def route_tools(\n",
        "    state: State,\n",
        ") -> Literal[\"tools\", \"__end__\"]:\n",
        "    if messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"stateにツールに関するメッセージが見つかりませんでした: {state}\")\n",
        "\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    return \"__end__\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_q1MFbrl-gVS"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    route_tools,\n",
        "    [\"tools\", \"__end__\"],\n",
        ")\n",
        "\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "mhSROt22-hy8",
        "outputId": "ca9483b8-1846-4b65-cc9e-87f0310d4a78"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvvyAiHo-jJu",
        "outputId": "54514511-8621-4e7c-829d-fb141b688b15"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "human_message = {\n",
        "    \"messages\": [HumanMessage(\"今日の東京の天気を教えて\")],\n",
        "    \"count\": 0,\n",
        "}\n",
        "\n",
        "for event in graph.stream(human_message):\n",
        "    for value in event.values():\n",
        "        value[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVWAraWu-kge"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
