{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGQrvXao8Ue5"
   },
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmgwxvC071EL",
    "outputId": "a70e637f-f7dd-4a9f-f6f5-9dce992bcee5"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "# OpenAI API キーの設定\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzCRyhnb9Kf6",
    "outputId": "88a3a00c-94db-4f9b-e9bc-532b018f772f"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain langgraph langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vXW4rC68Xd0"
   },
   "source": [
    "# 4.1 マルチエージェントシステムの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQGJiFm_8ko0"
   },
   "source": [
    "## 4.2.2 チャットボットの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGTXx5dG9BvR"
   },
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", model_kwargs={\"temperature\": 0})\n",
    "\n",
    "class State(TypedDict):\n",
    "    count: int\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def chatbot(state: State):\n",
    "    messages = [llm.invoke(state[\"messages\"])]\n",
    "    count = state[\"count\"] + 1\n",
    "    return {\n",
    "        \"messages\": messages,\n",
    "        \"count\": count,\n",
    "    }\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "OTFpGOgy9CYN",
    "outputId": "5d2657be-8ebb-4f6d-daa4-ae1678f319ad"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XC1svxRU9CVi",
    "outputId": "1d81751c-385f-472c-96ee-1777cbbf2000"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "human_message = HumanMessage(\"こんにちは\")\n",
    "\n",
    "for event in graph.stream({\"messages\": [human_message], \"count\": 0}):\n",
    "    for value in event.values():\n",
    "        print(f\"### ターン{value['count']} ###\")\n",
    "        value[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlU1rU3W9CTS"
   },
   "outputs": [],
   "source": [
    "# ペルソナの設定\n",
    "\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    system_message = SystemMessage(\"あなたは、元気なエンジニアです。元気に返答してください。\")\n",
    "    messages = [llm.invoke([system_message] + state[\"messages\"])]\n",
    "    count = state[\"count\"] + 1\n",
    "    return {\n",
    "        \"messages\": messages,\n",
    "        \"count\": count,\n",
    "    }\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMyO_d8z9CQq",
    "outputId": "5c8adb6c-465c-4523-ad36-bb774507e6fb"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "human_message = HumanMessage(\"上手くデバッグができません\")\n",
    "\n",
    "for event in graph.stream({\"messages\": [human_message], \"count\": 0}):\n",
    "    for value in event.values():\n",
    "        print(f\"### ターン{value['count']} ###\")\n",
    "        value[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHXlL21f8klr"
   },
   "source": [
    "## 4.2.3 複数のエージェントの接続"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHD2smCU8kiz"
   },
   "source": [
    "### 3つのエージェントの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_SGC-du_nt2"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "import functools\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "def agent_with_persona(state: State, name: str, traits: str):\n",
    "    system_message_template = SystemMessagePromptTemplate.from_template(\n",
    "        \"あなたの名前は{name}です。\\nあなたの性格は以下のとおりです。\\n\\n{traits}\"\n",
    "    )\n",
    "    system_message = system_message_template.format(name=name, traits=traits)\n",
    "\n",
    "    message = HumanMessage(\n",
    "        content=llm.invoke([system_message, *state[\"messages\"]]).content,\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"messages\": [message],\n",
    "    }\n",
    "\n",
    "kenta_traits = \"\"\"\\\n",
    "- アクティブで冒険好き\n",
    "- 新しい経験を求める\n",
    "- アウトドア活動を好む\n",
    "- SNSでの共有を楽しむ\n",
    "- エネルギッシュで社交的\"\"\"\n",
    "\n",
    "mari_traits = \"\"\"\\\n",
    "- 穏やかでリラックス志向\n",
    "- 家族を大切にする\n",
    "- 静かな趣味を楽しむ\n",
    "- 心身の休養を重視\n",
    "- 丁寧な生活を好む\"\"\"\n",
    "\n",
    "yuta_traits = \"\"\"\\\n",
    "- バランス重視\n",
    "- 柔軟性がある\n",
    "- 自己啓発に熱心\n",
    "- 伝統と現代の融合を好む\n",
    "- 多様な経験を求める\"\"\"\n",
    "\n",
    "kenta = functools.partial(agent_with_persona, name=\"kenta\", traits=kenta_traits)\n",
    "mari = functools.partial(agent_with_persona, name=\"mari\", traits=mari_traits)\n",
    "yuta = functools.partial(agent_with_persona, name=\"yuta\", traits=yuta_traits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2KaKU0-8kf2"
   },
   "source": [
    "### 3つのエージェントが順番に回答するシステム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvcbBjzf_wtB"
   },
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sw6t5kaDAY_Q"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"kenta\", kenta)\n",
    "graph_builder.add_node(\"mari\", mari)\n",
    "graph_builder.add_node(\"yuta\", yuta)\n",
    "\n",
    "graph_builder.add_edge(START, \"kenta\")\n",
    "graph_builder.add_edge(\"kenta\", \"mari\")\n",
    "graph_builder.add_edge(\"mari\", \"yuta\")\n",
    "graph_builder.add_edge(\"yuta\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "fny-Bwr_AZnR",
    "outputId": "caa45ccd-e549-401b-badb-e94b7129c2ca"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIM6amN9AdHA",
    "outputId": "23a08647-d075-4f0b-a3d5-71127e9a13ef"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "human_message = HumanMessage(\"休日の過ごし方について、建設的に議論してください。\")\n",
    "\n",
    "for event in graph.stream({\"messages\": [human_message]}):\n",
    "    for value in event.values():\n",
    "        value[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1k-Vxu08kdN"
   },
   "source": [
    "### 3つのエージェントが一斉に回答するシステム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5KR9ZG7AiFt"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"kenta\", kenta)\n",
    "graph_builder.add_node(\"mari\", mari)\n",
    "graph_builder.add_node(\"yuta\", yuta)\n",
    "\n",
    "\n",
    "graph_builder.add_edge(START, \"kenta\")\n",
    "graph_builder.add_edge(START, \"mari\")\n",
    "graph_builder.add_edge(START, \"yuta\")\n",
    "graph_builder.add_edge(\"kenta\", END)\n",
    "graph_builder.add_edge(\"mari\", END)\n",
    "graph_builder.add_edge(\"yuta\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "678fnvYyAnis",
    "outputId": "39f36816-1890-46b1-be0f-ba50779f24bd"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7F4qNwWAu04",
    "outputId": "639b0b81-d4b6-4fc5-dc4f-edbcbe44c233"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "human_message = HumanMessage(\"休日の過ごし方について、建設的に議論してください。\")\n",
    "\n",
    "for event in graph.stream({\"messages\": [human_message]}):\n",
    "    for value in event.values():\n",
    "        value[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q-P5_Wr8kaD"
   },
   "source": [
    "### 3つのエージェントから選択されたエージェントが回答するシステム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnYkNzNmAyf8"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    next: str\n",
    "\n",
    "member_dict = {\n",
    "    \"kenta\": kenta_traits,\n",
    "    \"mari\": mari_traits,\n",
    "    \"yuta\": yuta_traits,\n",
    "}\n",
    "\n",
    "#1 スキーマの設定\n",
    "class RouteSchema(BaseModel):\n",
    "    next: Literal[\"kenta\", \"mari\", \"yuta\"] = Field(..., description=\"次に発言する人\")\n",
    "\n",
    "#2 監督者の作成\n",
    "def supervisor(state: State):\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\n",
    "        \"あなたは以下の作業者間の会話を管理する監督者です：{members}。\"        \"各メンバーの性格は以下の通りです。\"        \"{traits_description}\"        \"与えられたユーザーリクエストに対して、次に発言する人を選択してください。\"    )\n",
    "\n",
    "    members = \", \".join(list(member_dict.keys()))\n",
    "    traits_description = \"\\n\".join([f\"**{name}**\\n{traits}\" for name, traits in member_dict.items()])\n",
    "\n",
    "    system_message = system_message.format(members=members, traits_description=traits_description)\n",
    "\n",
    "    llm_with_format = llm.with_structured_output(RouteSchema)\n",
    "\n",
    "    next = llm_with_format.invoke([system_message] + state[\"messages\"]).next\n",
    "    return {\"next\": next}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Tesz8AvBMBg"
   },
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"supervisor\", supervisor)\n",
    "graph_builder.add_node(\"kenta\", kenta)\n",
    "graph_builder.add_node(\"mari\", mari)\n",
    "graph_builder.add_node(\"yuta\", yuta)\n",
    "\n",
    "graph_builder.add_edge(START, \"supervisor\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda state: state[\"next\"],\n",
    "    {\"kenta\": \"kenta\", \"mari\": \"mari\", \"yuta\": \"yuta\"},\n",
    ")\n",
    "\n",
    "for member in [\"kenta\", \"mari\", \"yuta\"]:\n",
    "    graph_builder.add_edge(member, END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "C_745661BQmW",
    "outputId": "65c802d3-8ce6-4b0a-cec2-276c32820528"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZL-CGsZBiWU",
    "outputId": "36639c7b-343e-4a0a-a61f-c3544b1bb349"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "human_message = HumanMessage(\"休日のまったりした過ごし方を教えて\")\n",
    "for event in graph.stream({\"messages\": [human_message]}):\n",
    "    for value in event.values():\n",
    "        if \"next\" in value:\n",
    "            print(f\"次に発言する人: {value['next']}\")\n",
    "        elif \"messages\" in value:\n",
    "            value[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sek8AwOc8kWU"
   },
   "source": [
    "## 4.2.4 ツールの使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVq61UlQ_ePY"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "# Tavily API キーの設定\n",
    "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Jf8Lmrh78vS"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "#1 ツールの作成\n",
    "tavily_tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "#2 ツールの紐づけ\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tool = llm.bind_tools([tavily_tool])\n",
    "\n",
    "#3 ツールを使ったチャットボットの作成\n",
    "def chatbot(state: State):\n",
    "    messages = [llm_with_tool.invoke(state[\"messages\"])]\n",
    "    return {\n",
    "        \"messages\": messages,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LO7MA1Iq-Gxx"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class ToolNode:\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, state: State):\n",
    "        #1 最後のメッセージを取得\n",
    "        if messages := state.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"入力にメッセージが見つかりません\")\n",
    "\n",
    "        #2 ツールの実行\n",
    "        tool_messages = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            #2.1 エージェントが指定したnameとargsを元にツールを実1行\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            #2.2 ツールの実行結果をメッセージとして追加\n",
    "            tool_messages.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result, ensure_ascii=False),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"messages\": tool_messages,\n",
    "        }\n",
    "\n",
    "tool_node = ToolNode([tavily_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNfI5sO7-e2e"
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    ") -> Literal[\"tools\", \"__end__\"]:\n",
    "    if messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"stateにツールに関するメッセージが見つかりませんでした: {state}\")\n",
    "\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return \"__end__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_q1MFbrl-gVS"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    [\"tools\", \"__end__\"],\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "mhSROt22-hy8",
    "outputId": "ca9483b8-1846-4b65-cc9e-87f0310d4a78"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TvvyAiHo-jJu",
    "outputId": "54514511-8621-4e7c-829d-fb141b688b15"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "human_message = {\n",
    "    \"messages\": [HumanMessage(\"今日の東京の天気を教えて\")],\n",
    "    \"count\": 0,\n",
    "}\n",
    "\n",
    "for event in graph.stream(human_message):\n",
    "    for value in event.values():\n",
    "        value[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVWAraWu-kge"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
