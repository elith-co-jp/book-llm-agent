{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2e1J3p4Dqu2"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFUMuI4bEGcj",
        "outputId": "4354b1d2-2843-49f1-fcdb-f9ce435b1e6c"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# OpenAI API キーの設定\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgTjtbZuEVxn",
        "outputId": "751f2469-f062-4818-c4ff-dab98be54d16"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langgraph langchain-openai langchain-community langchain-experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKUsbzjKDjYg"
      },
      "source": [
        "# 4.3. マルチエージェントの活用\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEh3ONBaDjSk"
      },
      "source": [
        "## 4.3.1. 数学の問題を解かせよう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Piv2lKP6JK0v"
      },
      "outputs": [],
      "source": [
        "!pip install -q sympy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5pCY8g12EoPe"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    problem: str\n",
        "    first_flag: bool\n",
        "    end_flag: bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "BigURL1yEoNc"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "#1 Python実行用のツール\n",
        "repl = PythonREPL()\n",
        "\n",
        "#2 コード部分を抜き出す関数\n",
        "def extract_code(input_string: str):\n",
        "    pattern = r\"```(.*?)```\"\n",
        "    match = re.findall(pattern, input_string, flags=re.DOTALL)\n",
        "\n",
        "    queries = \"\"\n",
        "    for m in match:\n",
        "        query = m.replace(\"python\", \"\").strip()\n",
        "        queries += query + \"\\n\"\n",
        "    return queries\n",
        "\n",
        "#3 ユーザープロキシエージェントの定義\n",
        "INITIAL_PROMPT = \"\"\"\\\n",
        "Pythonを使って数学の問題を解いてみましょう。\n",
        "\n",
        "クエリ要件：\n",
        "常に出力には'print'関数を使用し、小数ではなく分数や根号形式を使用してください。\n",
        "sympyなどのパッケージを利用しても構いません。\n",
        "以下のフォーマットに従ってコードを書いてください。\n",
        "```python\n",
        "# あなたのコード\n",
        "```\n",
        "\n",
        "まず、問題を解くための主な考え方を述べてください。問題を解くためには以下の3つの方法から選択できます：\n",
        "ケース1：問題が直接Pythonコードで解決できる場合、プログラムを書いて解決してください。必要に応じてすべての可能な配置を列挙しても構いません。\n",
        "ケース2：問題が主に推論で解決できる場合、自分で直接解決してください。\n",
        "ケース3：上記の2つの方法では対処できない場合、次のプロセスに従ってください：\n",
        "1. 問題をステップバイステップで解決する（ステップを過度に細分化しないでください）。\n",
        "2. Pythonを使って問い合わせることができるクエリ（計算や方程式など）を取り出します。\n",
        "3. 結果を私に教えてください。\n",
        "4. 結果が正しいと思う場合は続行してください。結果が無効または予期しない場合は、クエリまたは推論を修正してください。\n",
        "\n",
        "すべてのクエリが実行され、答えを得た後、答えを \\\\boxed{{}} に入れてください。\n",
        "答え以外、例えば変数を\\\\boxed{{}}に入れたり、\\\\boxed{{}}を単体で使用しないで下さい。\n",
        "\\\\boxed{{}}の有無で答えが出たかを管理しています。最終的な答えが出た時以外は、\\\\boxed{{}}を使用しないでください。\n",
        "回答が得られた場合は、シンプルに表示して下さい。追加の出力などはしないでください。\n",
        "\n",
        "問題文：{problem}\n",
        "\"\"\"\n",
        "\n",
        "def user_proxy_agent(state: State):\n",
        "    if state[\"first_flag\"]:\n",
        "        message = INITIAL_PROMPT.format(problem=state[\"problem\"])\n",
        "    else:\n",
        "        last_message = state[\"messages\"][-1].content\n",
        "        code = extract_code(last_message)\n",
        "        if code:\n",
        "            message = repl.run(code)\n",
        "        else:\n",
        "            message = \"続けてください。クエリが必要になるまで問題を解き続けてください。（答えが出た場合は、\\\\boxed{{}} に入れてください。）\",\n",
        "    message = HumanMessage(message)\n",
        "    return {\"messages\": [message], \"first_flag\": False}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "4m5kr76zEoLW"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# 回答を抜き出す関数\n",
        "def extract_boxed(input_string: str):\n",
        "    pattern = r\"\\\\boxed\\{.*?\\}\"\n",
        "    matches = re.findall(pattern, input_string)\n",
        "    return [m.replace(\"\\\\boxed{\", \"\").replace(\"}\", \"\") for m in matches]\n",
        "\n",
        "#  LLMエージェントを定義した関数\n",
        "def llm_agent(state: State):\n",
        "    message = llm.invoke(state[\"messages\"])\n",
        "    content = message.content\n",
        "    boxed = extract_boxed(content)\n",
        "    end_flag = False\n",
        "    if boxed:\n",
        "        end_flag = True\n",
        "    return {\"messages\": [message], \"end_flag\": end_flag}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "45wPtyjeEoIq"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "graph_builder.add_node(\"llm_agent\", llm_agent)\n",
        "graph_builder.add_node(\"user_proxy_agent\", user_proxy_agent)\n",
        "\n",
        "graph_builder.add_edge(START, \"user_proxy_agent\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"llm_agent\",\n",
        "    lambda state: state[\"end_flag\"],\n",
        "    {True: END, False: \"user_proxy_agent\"}\n",
        ")\n",
        "graph_builder.add_edge(\"user_proxy_agent\", \"llm_agent\")\n",
        "\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "uewP3Yh7EoGS",
        "outputId": "706ba059-dc72-4138-b4d2-77b8cd978c03"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GTu5pCeEoB5",
        "outputId": "f76a6c5a-198f-40d8-a7d8-af48916f7956"
      },
      "outputs": [],
      "source": [
        "problem = \"\"\"\\\n",
        "問題: 偽の金塊は、コンクリートの立方体を金色のペイントで覆うことによって作られます。\n",
        "ペイントのコストは立方体の表面積に比例し、コンクリートのコストは体積に比例します。\n",
        "1インチの立方体を作るコストが$1.30であり、2インチの立方体を作るコストが$6.80であるとき、3インチの立方体を作るコストはいくらになりますか？\"\"\"\n",
        "\n",
        "\n",
        "for event in graph.stream({\"problem\": problem, \"first_flag\": True}):\n",
        "    for value in event.values():\n",
        "        value[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "403Y2hADDjNO"
      },
      "source": [
        "## 4.3.2. 議論させてみよう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "XehsDu1VHwCO"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    debate_topic: str\n",
        "    judged: bool\n",
        "    round: int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "mmFesZ2EIUWj"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "def cot_agent(\n",
        "    state: State,\n",
        "):\n",
        "    system_message = (\n",
        "        \"与えられた議題に対し、ステップバイステップで考えてから回答してください。\"\n",
        "        \"議題：{debate_topic}\"\n",
        "    )\n",
        "    system_message = SystemMessage(\n",
        "        system_message.format(debate_topic=state[\"debate_topic\"])\n",
        "    )\n",
        "    message = HumanMessage(\n",
        "        content=llm.invoke([system_message]).content, name=\"CoT\"\n",
        "    )\n",
        "\n",
        "    return {\"messages\": [message]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "nfBdd_h5Hv9k"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "import functools\n",
        "\n",
        "def debater(\n",
        "    state: State,\n",
        "    name: str,\n",
        "    position: str,\n",
        "):\n",
        "    system_message = (\n",
        "        \"あなたはディベーターです。ディベート大会へようこそ。\"\n",
        "        \"私たちの目的は正しい答えを見つけることですので、お互いの視点に完全に同意する必要はありません。\"\n",
        "        \"ディベートのテーマは以下の通りです：{debate_topic}\"\n",
        "        \"\"\n",
        "        \"{position}\"\n",
        "    )\n",
        "\n",
        "    debate_topic = state[\"debate_topic\"]\n",
        "    system_message = SystemMessage(\n",
        "        system_message.format(debate_topic=debate_topic, position=position)\n",
        "    )\n",
        "    message = HumanMessage(\n",
        "        content=llm.invoke([system_message, *state[\"messages\"]]).content,\n",
        "        name=name,\n",
        "    )\n",
        "    return {\"messages\": [message]}\n",
        "\n",
        "\n",
        "affirmative_debator = functools.partial(\n",
        "    debater,\n",
        "    name=\"Affirmative_Debater\",\n",
        "    position=\"あなたは肯定側です。あなたの見解を簡潔に述べてください。否定側の意見が与えられた場合は、それに反対して理由を簡潔に述べてください。\"\n",
        ")\n",
        "negative_debator = functools.partial(\n",
        "    debater,\n",
        "    name=\"Negative_Debater\",\n",
        "    position=\"あなたは否定側です。肯定側の意見に反対し、あなたの理由を簡潔に説明してください。\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "V85r_fHIHv6a"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "\n",
        "class JudgeSchema(BaseModel):\n",
        "    judged: bool = Field(..., description=\"勝者が決まったかどうか\")\n",
        "    answer: str = Field(description=\"議題に対する結論とその理由\")\n",
        "\n",
        "\n",
        "def judger(state: State):\n",
        "    system_message = (\n",
        "        \"あなたは司会者です。\"\n",
        "        \"ディベート大会に2名のディベーターが参加します。\"\n",
        "        \"彼らは{debate_topic}について自分の回答を発表し、それぞれの視点について議論します。\"\n",
        "        \"各ラウンドの終わりに、あなたは両者の回答を評価していき、ディベートの勝者を判断します。\"\n",
        "        \"判定が難しい場合は、次のラウンドで判断してください。\"\n",
        "    )\n",
        "    system_message = SystemMessage(\n",
        "        system_message.format(debate_topic=state[\"debate_topic\"])\n",
        "    )\n",
        "\n",
        "    llm_with_format = llm.with_structured_output(JudgeSchema)\n",
        "    res = llm_with_format.invoke([system_message, *state[\"messages\"]])\n",
        "    messages = []\n",
        "\n",
        "    if res.judged:\n",
        "        message = HumanMessage(res.answer)\n",
        "        messages.append(message)\n",
        "    return {\n",
        "        \"messages\": messages,\n",
        "        \"judged\": res.judged\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "TBKEZudkHv3d"
      },
      "outputs": [],
      "source": [
        "def round_monitor(state: State, max_round: int):\n",
        "    round = state[\"round\"] + 1\n",
        "    if state[\"round\"] < max_round:\n",
        "        return {\"round\": round}\n",
        "    else:\n",
        "        return {\n",
        "            \"messages\": [HumanMessage(\n",
        "                \"最終ラウンドなので、勝者を決定し、議題に対する結論とその理由を述べてください。\"\n",
        "            )],\n",
        "            \"round\": round,\n",
        "        }\n",
        "\n",
        "round_monitor = functools.partial(round_monitor, max_round=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "FBA4XLs3Hv0z"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "graph_builder.add_node(\"cot_agent\", cot_agent)\n",
        "graph_builder.add_node(\"affirmative_debator\", affirmative_debator)\n",
        "graph_builder.add_node(\"negative_debator\", negative_debator)\n",
        "graph_builder.add_node(\"judger\", judger)\n",
        "graph_builder.add_node(\"round_monitor\", round_monitor)\n",
        "\n",
        "graph_builder.add_edge(START, \"cot_agent\")\n",
        "graph_builder.add_edge(\"cot_agent\", \"affirmative_debator\")\n",
        "graph_builder.add_edge(\"affirmative_debator\", \"negative_debator\")\n",
        "graph_builder.add_edge(\"negative_debator\", \"round_monitor\")\n",
        "graph_builder.add_edge(\"round_monitor\", \"judger\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"judger\",\n",
        "    lambda state: state[\"judged\"],\n",
        "    {True: END, False: \"affirmative_debator\"}\n",
        ")\n",
        "\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "OOCyn8e0HvyW",
        "outputId": "6227e80d-46ca-477b-d96f-e295f6546e91"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQuwDrrSHvvh",
        "outputId": "53072ae3-b75e-4a2e-ddd4-87c97a8b8cb9"
      },
      "outputs": [],
      "source": [
        "inputs = {\n",
        "    \"messages\": [],\n",
        "    \"debate_topic\": \"戦争は必要か？\",\n",
        "    \"judged\": False,\n",
        "    \"round\": 0,\n",
        "}\n",
        "\n",
        "for event in graph.stream(inputs):\n",
        "    for value in event.values():\n",
        "        try:\n",
        "            value[\"messages\"][-1].pretty_print()\n",
        "        except:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaSUFgy-DlMW"
      },
      "source": [
        "## 4.3.3. 回答を洗練させよう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlIsAPgnDSo-",
        "outputId": "e2ccb2a7-4f38-4203-e7ad-d53883e99490"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain-google-genai\n",
        "!pip install -q langchain-anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DY6aQ7pJbTk",
        "outputId": "bbdf1f95-1d5b-447a-dcb4-11bcb1b5936f"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Google API キーの設定\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Anthropic API キーの設定\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get('ANTHROPIC_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "OKbA3y37JTmv"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm_openai = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "llm_anthropic = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
        "llm_google = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "wdBjWZVXJ4S8"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    human_message: HumanMessage\n",
        "    messages: Annotated[list, add_messages]\n",
        "    prev_messages: list[AIMessage]\n",
        "    layer_cnt: int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "sq3iVg26J6sc"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from typing import Union\n",
        "\n",
        "\n",
        "aggregater_system_message_template = \"\"\"\\\n",
        "最新のユーザーの質問に対して、さまざまなLLMからの回答が提供されています。あなたの任務は、これらの回答を統合して、単一の高品質な回答を作成することです。\n",
        "提供された回答に含まれる情報を批判的に評価し、一部の情報が偏っていたり誤っていたりする可能性があることを認識することが重要です。\n",
        "回答を単に複製するのではなく、正確で包括的な返答を提供してください。\n",
        "回答が良く構造化され、一貫性があり、最高の精度と信頼性の基準を満たすようにしてください。\n",
        "\n",
        "{prev_messages}\"\"\"\n",
        "\n",
        "def agent(state: State, llm: Union[ChatOpenAI, ChatAnthropic, ChatGoogleGenerativeAI], name: str):\n",
        "    input_messages = []\n",
        "    if len(state[\"prev_messages\"]) > 0:\n",
        "        prev_messages = [f\"{i+1}. {message.content}\" for i, message in enumerate(state[\"prev_messages\"])]\n",
        "        prev_messages = \"\\n\".join(prev_messages)\n",
        "\n",
        "        aggregater_system_message = SystemMessage(\n",
        "            aggregater_system_message_template.format(prev_messages=prev_messages),\n",
        "        )\n",
        "\n",
        "        input_messages.append(aggregater_system_message)\n",
        "\n",
        "    input_messages.append(state[\"human_message\"])\n",
        "\n",
        "    message = llm.invoke(input_messages)\n",
        "    message.name = name\n",
        "\n",
        "    return {\"messages\": [message]}\n",
        "\n",
        "agent_openai = partial(agent, llm=llm_openai, name=\"openai\")\n",
        "agent_anthropic = partial(agent, llm=llm_anthropic, name=\"anthropic\")\n",
        "agent_google = partial(agent, llm=llm_google, name=\"google\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "_Yql6MGSKAIg"
      },
      "outputs": [],
      "source": [
        "def update(state: State, num_agents: int):\n",
        "    return {\n",
        "        \"prev_messages\": state[\"messages\"][-num_agents:],\n",
        "        \"layer_cnt\": state[\"layer_cnt\"] + 1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "D2hYclt1KBlC"
      },
      "outputs": [],
      "source": [
        "def router(\n",
        "    state: State,\n",
        "    num_layers: int,\n",
        "    agent_name_list: list[str]\n",
        "):\n",
        "    if state[\"layer_cnt\"] < num_layers:\n",
        "        return agent_name_list\n",
        "    else:\n",
        "        return \"final_agent\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "IFd-9LuQKDCz"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "num_layers = 3\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "agent_dict = {\n",
        "    \"openai\": agent_openai,\n",
        "    \"anthropic\": agent_anthropic,\n",
        "    \"google\": agent_google,\n",
        "}\n",
        "\n",
        "graph_builder.add_node(\n",
        "    \"update\",\n",
        "    partial(update, num_agents=len(agent_dict))\n",
        ")\n",
        "graph_builder.add_node(\"final_agent\", agent_dict[\"openai\"])\n",
        "\n",
        "for agent_name, agent in agent_dict.items():\n",
        "    graph_builder.add_node(agent_name, agent)\n",
        "    graph_builder.add_edge(START, agent_name)\n",
        "    graph_builder.add_edge(agent_name, \"update\")\n",
        "\n",
        "agent_name_list = list(agent_dict.keys())\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"update\",\n",
        "    partial(router, num_layers=num_layers, agent_name_list=agent_name_list),\n",
        "    agent_name_list + [\"final_agent\"]\n",
        ")\n",
        "graph_builder.add_edge(\"final_agent\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "LOaI8azYKEcD",
        "outputId": "3966c76a-2804-4cf8-c1bf-807fa391e61d"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdYcAMfEKGM2",
        "outputId": "df42b40e-8fa3-4209-cd00-56fa257b150f"
      },
      "outputs": [],
      "source": [
        "human_message = HumanMessage(\"マルチエージェントについて教えて\")\n",
        "\n",
        "state = {\n",
        "    \"human_message\": human_message,\n",
        "    \"messages\": [],\n",
        "    \"prev_messages\": [],\n",
        "    \"layer_cnt\": 1\n",
        "}\n",
        "\n",
        "print(\"#################### Layer 1 ####################\")\n",
        "for event in graph.stream(state):\n",
        "    for value in event.values():\n",
        "        if \"messages\" in value:\n",
        "            value[\"messages\"][-1].pretty_print()\n",
        "        if \"layer_cnt\" in value:\n",
        "            print(f\"\\n\\n#################### Layer {value['layer_cnt']} ####################\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1kkzZKjKHhq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
